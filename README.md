# ğŸ“˜ DocumentaÃ§Ã£o do Projeto: **PrediÃ§Ã£o de Encaminhamento de Candidatos**

## ğŸ§  Objetivo

Criar um sistema inteligente capaz de prever se um candidato serÃ¡ **encaminhado para uma vaga** com base em suas informaÃ§Ãµes profissionais e acadÃªmicas. O pipeline inclui:

* PrÃ©-processamento de dados
* Engenharia de atributos
* Treinamento de modelo com balanceamento (SMOTE)
* OtimizaÃ§Ã£o de hiperparÃ¢metros (Optuna)
* API de inferÃªncia via FastAPI

---

## ğŸ—‚ Estrutura de DiretÃ³rios

```
.
â”œâ”€â”€ app.py                      # FastAPI com endpoint /predict
â”œâ”€â”€ compose.yaml               # Docker Compose para subir a API
â”œâ”€â”€ Dockerfile                 # Container Docker da aplicaÃ§Ã£o
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ models/                    # Modelos treinados e serializados
â”œâ”€â”€ eda/                       # AnÃ¡lises exploratÃ³rias (EDA)
â”œâ”€â”€ pipeline/                  # LÃ³gica de pipeline, feature engineering e modelo
â”œâ”€â”€ raw_data/                  # Dados brutos (nÃ£o versionados)
â””â”€â”€ tests/                     # Testes unitÃ¡rios e de integraÃ§Ã£o
```

---

## âš™ï¸ Como Funciona o Pipeline

### 1. PrÃ©-processamento (`pre_processing.py`)

Carrega os dados dos arquivos `applicants.json` e `prospects.json` e junta as informaÃ§Ãµes por `codigo`.

### 2. Feature Engineering (`feature_engineering.py`)

* Converte a remuneraÃ§Ã£o para numÃ©rico.
* Cria a variÃ¡vel alvo `y`: `1` se "Encaminhado", `0` caso contrÃ¡rio.
* Remove colunas irrelevantes para o modelo.

### 3. Treinamento do Modelo (`model_training.py`)

* OneHotEncoder + Imputer (categorias e nÃºmeros).
* Balanceamento com SMOTE.
* OtimizaÃ§Ã£o com Optuna (LightGBM).
* Salva modelo com `joblib`.

### 4. ExecuÃ§Ã£o da Pipeline (`pipeline.py`)

```bash
python -m pipeline.pipeline
```

---

## ğŸš€ API de InferÃªncia (FastAPI)

### ğŸ“¦ ExecuÃ§Ã£o Local

```bash
uvicorn app:app --reload
```

Ou com Docker:

```bash
docker compose up --build
```

### ğŸ“¥ Endpoint

**POST** `/predict`

**Request Body**:

```json
{
  "local": "SÃ£o Paulo",
  "objetivo": "Analista de Dados",
  "nivel_academico": "Superior",
  "ingles": "AvanÃ§ado",
  "espanhol": "BÃ¡sico",
  "remuneracao": 7000.0
}
```

**Resposta**:

```json
{
  "encaminhado": true,
  "probabilidade": 0.84,
  "dados_candidato": {...}
}
```

Acesse a documentaÃ§Ã£o Swagger automÃ¡tica em:
ğŸ‘‰ [`/docs`](http://localhost:8000/docs)

---

## ğŸ”¬ EDA (AnÃ¡lise ExploratÃ³ria)

Scripts em `eda/` mostram:

* DistribuiÃ§Ã£o de candidatos por nÃ­vel acadÃªmico
* RemuneraÃ§Ãµes
* EvoluÃ§Ã£o temporal das candidaturas
* Recrutadores com mais atividade

Execute individualmente os arquivos `eda_*.py` para anÃ¡lises.

---

## ğŸ§ª Testes

Executar todos os testes:

```bash
pytest tests/
```

Testes cobrem:

* PrÃ©-processamento
* Feature Engineering
* Treinamento
* Pipeline completa
* API (opcional de adicionar)

---

## ğŸ“¦ Requisitos

Instale via:

```bash
pip install -r requirements.txt
```

Inclui:

* `lightgbm`, `optuna`, `scikit-learn`, `imbalanced-learn`, `fastapi`, `uvicorn` etc.

---

## ğŸ“ ObservaÃ§Ãµes

* Os dados estÃ£o localizados em `raw_data/` (nÃ£o versionados por seguranÃ§a).
* O modelo treinado Ã© salvo em `models/modelo_lgbm_optuna.pkl`.
* O projeto segue boas prÃ¡ticas com modularizaÃ§Ã£o, pipeline clara e testes automatizados.
